{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HS_code.ipynb","provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2A9R_90MOfyj","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import time\n","import math\n","#Tfidf && LDA\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from scipy.spatial.distance import cosine\n","#pickle for save and load mode\n","import pickle\n","#KDtree\n","from scipy import spatial\n","#Text prerocessing\n","import string\n","import re\n","import logging\n","import pandas as pd\n","import numpy as np\n","from numpy import random\n","import gensim\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n","BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n","STOPWORDS = set(stopwords.words('english'))\n","#Increase stack limit\n","import sys\n","sys.setrecursionlimit(10000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqQKFI5tOoiF","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzQrHwpSOqfN","colab_type":"code","colab":{}},"source":["#DATA PART\n","DATA = '/content/drive/My Drive/Data'\n","CORPUS = '/content/drive/My Drive/Data/CORPUS'\n","LDAMODEL = '/content/drive/My Drive/Data/MODEL/LDAmodel'\n","VECTORIZEMODEL = '/content/drive/My Drive/Data/MODEL/VectorizeModel'\n","TFIDF = '/content/drive/My Drive/Data/TFIDF'\n","KDTREE = '/content/drive/My Drive/Data/KDTree'\n","MAINCORPUS = '/content/drive/My Drive/Data/preprocessed_copus.csv'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCmru380Or9l","colab_type":"code","colab":{}},"source":["#preprocessing\n","redundant_word = ['code', 'tel', 'fax', 'vat', 'hscode', 'h']\n","def preprocessing(text):\n","  try:\n","    text = text.lower()\n","    text = re.sub(r'\\d+', \" \", text) # delete number\n","    text = REPLACE_BY_SPACE_RE.sub(\" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = BAD_SYMBOLS_RE.sub(\" \", text) # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = text.translate(text.maketrans(\" \", \" \", string.punctuation))\n","    text = word_tokenize(text)\n","    text = [word for word in text if not word in STOPWORDS]\n","    text = [word for word in text if not word in redundant_word]\n","    stemmer= PorterStemmer()\n","    # lemmatizer=WordNetLemmatizer()\n","    text = [stemmer.stem(word) for word in text]\n","    # text = [lemmatizer.lemmatize(word) for word in text]\n","    text = ' '.join(word for word in text)\n","  except:\n","    print('exception: ' + text)\n","  return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SGxmx-cOwQ1","colab_type":"code","colab":{}},"source":["#Load LDA\n","LDAmodel = pickle.load(open(LDAMODEL, 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V3_5r4KHOxf1","colab_type":"code","colab":{}},"source":["#Load Vectorize\n","VectorizeModel = pickle.load(open(VECTORIZEMODEL, 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gMg7QdaDOyh9","colab_type":"code","colab":{}},"source":["#Load main corpus\n","MainCorpus = pd.read_csv(MAINCORPUS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xml-RcslOzpt","colab_type":"code","colab":{}},"source":["#Get $topic most similar topic\n","def findTopic(text, topic = 5):\n","  text = preprocessing(text)\n","\n","  topic_values = LDAmodel.transform(VectorizeModel.transform([text]))\n","\n","  tops = np.argpartition(topic_values[0], -topic)[-topic:]\n","  tops = tops[np.argsort(topic_values[0][tops])][::-1]\n","  \n","  return text, tops"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGKg9KO6O0xt","colab_type":"code","colab":{}},"source":["#Get $value_range records from topic\n","def findCorpus(topic_index, text, value_range = 5):\n","  tfidf_model = pickle.load(open(TFIDF + '/TFIDFtopic_' + str(topic_index), 'rb'))\n","  tfidf_vector = tfidf_model.transform([text]).todense()\n","\n","  kdtree_model = pickle.load(open(KDTREE + '/KDTree_' + str(topic_index), 'rb'))\n","  _, top_neigbors_index = kdtree_model.query(tfidf_vector[0], k = value_range)\n","\n","  corpus = pd.read_csv(CORPUS + '/topic_' + str(topic_index))\n","  corpus = corpus.loc[corpus['Unnamed: 0'].isin(top_neigbors_index[0])]\n","  \n","  return corpus"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"463qxdpCO3MN","colab_type":"code","colab":{}},"source":["#Concat corpuses toghether and cal the distances\n","def findHS(corpuses, text, record):\n","  output_dataframe = pd.DataFrame()\n","  for corpus in corpuses:\n","    output_dataframe = output_dataframe.append(corpus)\n","\n","  print(output_dataframe.head(25))\n","\n","  contents = output_dataframe['content'].as_matrix()\n","  contents = [e for e in contents] + [text]\n","\n","  distance_cal_tfidf = TfidfVectorizer()\n","  distance_vector = distance_cal_tfidf.fit_transform(contents).todense()\n","\n","  cosine_distance = [ 1 - cosine(element.reshape(-1), distance_vector[-1].reshape(-1)) for element in distance_vector[:-1]]\n","  \n","  output_dataframe['Distance'] = cosine_distance\n","\n","  return output_dataframe.sort_values(by = ['Distance'], ascending = False).head(record)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDDkXwAxVN7b","colab_type":"code","colab":{}},"source":["def mainHandler(text, topic = 5, value_range = 5, record = 10):\n","  # record must less than topic*value_range\n","  start_time = time.time()\n","\n","  preprocessed_text, tops = findTopic(text, topic)\n","  print('text: ' + str(preprocessed_text))\n","  print('---------------------------------------------')\n","  print('tops: ' + str(tops))\n","  print('---------------------------------------------')\n","\n","  corpuses = [findCorpus(topic_index, preprocessed_text, value_range) for topic_index in tops]\n","  \n","  print('---------------------------------------------')\n","  print('corpuses: ' + str(corpuses))\n","  print('---------------------------------------------')\n","\n","  output_df = findHS(corpuses, preprocessed_text, record)\n","\n","  print('---------------------------------------------')\n","  print('taked: ' + str(time.time() - start_time))\n","  print('---------------------------------------------')\n","\n","  return output_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9dUnyTQWZTB","colab_type":"code","colab":{}},"source":["text_sample = \"\"\"TWO (02)x40'HC CONTAINER(S) STC\\nELECTRIC WIRE\\nHS CODE: 854449\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7mOhGxAWZ1_","colab_type":"code","colab":{}},"source":["mainHandler(text_sample, 5, 5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jzxJ5tpBfnO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}